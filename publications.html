<html lang="fr"><head>
    <meta charset="utf-8">
    <head>
      <title>Publications - Axel Marmoret</title>
      <link rel="stylesheet" href="style/global.css">
      <link rel="stylesheet" href="style/profile.css">
      <link rel="stylesheet" href="style/index.css">
      <link rel="stylesheet" href="style/box_links.css">
<script>
function open_or_close(id){
  var myDiv = document.getElementById(id)
  if (myDiv.style.display=='block'){
    myDiv.style.display='none';
  } else {
    myDiv.style.display='block';
  }
};
</script>
    <script src="https://kit.fontawesome.com/12b596ef39.js" crossorigin="anonymous"></script>
    </head>
<body>
<div class="content">
  <div class="base">
    <div class="profile">
      <div class="photo">
        <img src="imgs/light_photo_sympa.jpeg"/>
      </div>
      <div class="info">
        <h1 class="name"><a href="index.html">Axel Marmoret</a></h1>
        <h2 class="job">PhD Student, Computer Science Engineer</h2>
      </div>
    </div>
    <div class="about">
      <h3>About Me</h3>
      Hello! My name is Axel Marmoret, I'm 25, and I'm a PhD Student at IRISA, Rennes in France.<br>
      I work on Machine Learning and Optimisation techniques for rerieving musical structure, based on its audio form.<br>
      I'm also a musician (mainly drummer, newly bassist!), and passionate about music.
    </div>
    <div class="contact">
      <h3>Contact Me</h3>
      <div class="email"><a href="mailto:axel.marmoret@irisa.fr"><i class="fas fa-envelope"></i><span>My mail adress</span></a></div>
      <div class="address"><a href="https://goo.gl/maps/3sw2My34x8vZPEP86" target="_blank"><i class="fas fa-map-marker"></i><span>Living in Rennes, France</span></a></div>
    </div>
    <div class="follow">
      <h3>Follow Me</h3>
      <div class="box">
        <a href="https://gitlab.inria.fr/amarmore" target="_blank"><i class="fab fa-gitlab "></i></a>
        <a href="https://hal.archives-ouvertes.fr/search/index/?q=%2A&authFullName_s=Axel+Marmoret" target="_blank"><i class="far fa-file-alt"></i></a>
        <a href="https://fr.linkedin.com/in/axel-marmoret-732491136" target="_blank"><i class="fab fa-linkedin"></i></a>
        <a href="https://open.spotify.com/user/e-xa" target="_blank"><i class="fab fa-spotify"></i></a>
      </div>
    </div>
  </div>
  <div class="func">
    <ul id="navigation">
      <li><a href="research.html">Research</a></li>
       <li><a href="resume.html">Resume</a></li>
       <li><a href="publications.html">Publications</a></li>
       <li><a href="codes.html">Codes</a></li>
       <li><a href="resources.html">Resources</a></li>
    </ul>
    <h1>Conference Papers</h1>
    <h2>Accepted</h2>
    <div class="content_block">
      <h2>Uncovering Audio Patterns in Music with Nonnegative Tucker Decomposition for Structural Segmentation.</h2>
      Axel Marmoret, Jérémy Cohen, Nancy Bertin, Frédéric Bimbot. ISMIR 2020 - 21st International Society for Music Information Retrieval, Oct 2020, Montréal (Online), Canada.
      <br><br>
        <div class="box">
          <a href="javascript:void(0);" onclick="open_or_close('uncov_abstract')"><i class="fas fa-info-circle"></i></a>
          <a href="javascript:void(0);" onclick="open_or_close('uncov_bibtex')"><i class="fas fa-quote-left"></i></a>
          <a href="https://hal.archives-ouvertes.fr/hal-02928733v1" target="_blank"><i class="fas fa-unlock-alt"></i></a>
          <a href="https://gitlab.inria.fr/amarmore/musicntd/-/tree/0.1.0" target="_blank"><i class="fab fa-gitlab"></i></a>
          <a href="https://youtu.be/qN8_y-k9KxI" target="_blank"><i class="fab fa-youtube"></i></a>
        </div>
    <div id="uncov_bibtex" class="hidden_content_block">
      <div class="citation_content">
          <p>@inproceedings{marmoret2020uncovering,
  title={Uncovering Audio Patterns in Music with Nonnegative Tucker Decomposition for Structural Segmentation},
  author={Marmoret, Axel and Cohen, Jeremy and Bertin, Nancy and Bimbot, Frederic},
  booktitle={ISMIR 2020-21st International Society for Music Information Retrieval},
  year={2020}}</p>
      </div>
    </div>
    <div id="uncov_abstract" class="hidden_content_block">
      <div class="citation_content">
          <p>Abstract: Recent work has proposed the use of tensor decomposition to model repetitions and to separate tracks in loop-based electronic music.
          The present work investigates further on the ability of Nonnegative Tucker Decompositon (NTD) to uncover musical patterns and structure in pop songs in their audio form.
          Exploiting the fact that NTD tends to express the content of bars as linear combinations of a few patterns, we illustrate the ability of the decomposition to capture and single out repeated motifs in the corresponding compressed space, which can be interpreted from a musical viewpoint.
          The resulting features also turn out to be efficient for structural segmentation, leading to experimental results on the RWC Pop data set which are potentially challenging state-of-the-art approaches that rely on extensive example-based learning schemes.
        </p>
      </div>
    </div>
  </div>

  <div class="content_block">
    <h2>Barwise Compression Schemes for Audio-Based Music Structure Analysis </h2>
    Axel Marmoret, Jérémy Cohen, Frédéric Bimbot. SMC 2022 - 19th Sound and Music Computing Conference, Jun 2022, Saint-Etienne, France.
      <div class="box">
        <a href="javascript:void(0);" onclick="open_or_close('barcomp_abstract')"><i class="fas fa-info-circle"></i></a>
        <a href="javascript:void(0);" onclick="open_or_close('barcomp_bibtex')"><i class="fas fa-quote-left"></i></a>
        <a href="https://hal.archives-ouvertes.fr/hal-03600873" target="_blank"><i class="fas fa-unlock-alt"></i></a>
        <a href="https://gitlab.inria.fr/amarmore/barwisemusiccompression" target="_blank"><i class="fab fa-gitlab"></i></a>
      </div>
  <div id="barcomp_bibtex" class="hidden_content_block">
    <div class="citation_content">
        <p>@article{marmoret2022barwise,
  title={Barwise Compression Schemes for Audio-Based Music Structure Analysis},
  author={Marmoret, Axel and Cohen, J{\'e}r{\'e}my E and Bimbot, Fr{\'e}d{\'e}ric},
  journal={{Proceedings of the 19th Sound and Music Computing Conference}},
  year={2022},
  doi= {10.5281/zenodo.6822204}}</p>
    </div>
  </div>
  <div id="barcomp_abstract" class="hidden_content_block">
    <div class="citation_content">
        <p>Abstract: Music Structure Analysis (MSA) consists in segmenting a music piece in several distinct sections. We approach MSA within a compression framework, under the hypothesis that the structure is more easily revealed by a simplified representation of the original content of the song. More specifically, under the hypothesis that MSA is correlated with similarities occurring at the bar scale, this article introduces the use of linear and non-linear compression schemes on barwise audio signals. Compressed representations capture the most salient components of the different bars in the song and are then used to infer the song structure using a dynamic programming algorithm. This work explores both low-rank approximation models such as Principal Component Analysis or Nonnegative Matrix Factorization and ``piece-specific'' Auto-Encoding Neural Networks, with the objective to learn latent representations specific to a given song. Such approaches do not rely on supervision nor annotations, which are well-known to be tedious to collect and possibly ambiguous in MSA description. In our experiments, several unsupervised compression schemes achieve a level of performance comparable to that of state-of-the-art supervised methods (for 3s tolerance) on the RWC-Pop dataset, showcasing the importance of the barwise compression processing for MSA.
      </p>
    </div>
  </div>
</div>

  <div class="content_block">
    <h2>Semi-Supervised Convolutive NMF for Automatic Piano Transcription</h2>
    Haoran Wu, Axel Marmoret, Jérémy Cohen. SMC 2022 - 19th Sound and Music Computing Conference, Jun 2022, Saint-Etienne, France.
      <div class="box">
        <a href="javascript:void(0);" onclick="open_or_close('cnmf_abstract')"><i class="fas fa-info-circle"></i></a>
        <a href="javascript:void(0);" onclick="open_or_close('cnmf_bibtex')"><i class="fas fa-quote-left"></i></a>
        <a href="https://hal.archives-ouvertes.fr/hal-03608497" target="_blank"><i class="fas fa-unlock-alt"></i></a>
        <a href="https://github.com/cohenjer/TransSSCNMF" target="_blank"><i class="fab fa-github"></i></a>
      </div>
  <div id="cnmf_bibtex" class="hidden_content_block">
    <div class="citation_content">
        <p>@article{wu2022semi,
  title={Semi-Supervised Convolutive NMF for Automatic Music Transcription},
  author={Wu, Haoran and Marmoret, Axel and Cohen, J{\'e}r{\'e}my E},
  journal={{Proceedings of the 19th Sound and Music Computing Conference}},
  year={2022},
  doi= {10.5281/zenodo.6822204}}</p>
    </div>
  </div>
  <div id="cnmf_abstract" class="hidden_content_block">
    <div class="citation_content">
        <p>Abstract: Automatic Music Transcription, which consists in transforming an audio recording of a musical performance into symbolic format, remains a difficult Music Information Retrieval task. In this work, which focuses on piano transcription, we propose a semi-supervised approach using low-rank matrix factorization techniques, in particular Convolutive Nonnegative Matrix Factorization. In the semi-supervised setting, only a single recording of each individual notes is required. We show on the MAPS dataset that the proposed semi-supervised CNMF method performs better than state-of-the-art low-rank factorization techniques and a little worse than supervised deep learning state-of-the-art methods, while however suffering from generalization issues.
      </p>
    </div>
  </div>
</div>
<div class="content_block">
  <h2>Nonnegative Tucker Decomposition with Beta-divergence for Music Structure Analysis of audio signals.</h2>
  Axel Marmoret, Florian Voorwinden, Valentin Leplat, Jérémy E Cohen, Frédéric Bimbot. arXiv preprint arXiv:2110.14434 - GRETSI 2022, Sep 2022, Nancy, France.
  <div class="box">
    <a href="javascript:void(0);" onclick="open_or_close('nonnegative_abstract')"><i class="fas fa-info-circle"></i></a>
    <a href="javascript:void(0);" onclick="open_or_close('nonnegative_bibtex')"><i class="fas fa-quote-left"></i></a>
    <a href="https://hal.archives-ouvertes.fr/hal-03409508v1" target="_blank"><i class="fas fa-unlock-alt"></i></a>
    <a href="https://gitlab.inria.fr/amarmore/nonnegative-factorization/-/tree/v0.2.0" target="_blank"><i class="fab fa-gitlab"></i></a>
  </div>
  <div id="nonnegative_bibtex" class="hidden_content_block">
    <div class="citation_content">
      <p>@article{marmoret2021nonnegative,
        title={Nonnegative Tucker Decomposition with Beta-divergence for Music Structure Analysis of audio signals},
        author={Marmoret, Axel and Voorwinden, Florian and Leplat, Valentin and Cohen, J{\'e}r{\'e}my E and Bimbot, Fr{\'e}d{\'e}ric},
        journal={arXiv preprint arXiv:2110.14434},
        year={2022}}</p>
      </div>
    </div>
    <div id="nonnegative_abstract" class="hidden_content_block">
      <div class="citation_content">
        <p>Abstract: Nonnegative Tucker Decomposition (NTD), a tensor decomposition model, has received increased interest in the recent years because of its ability to blindly extract meaningful patterns in tensor data.
          Nevertheless, existing algorithms to compute NTD are mostly designed for the Euclidean loss.
          On the other hand, NTD has recently proven to be a powerful tool in Music Information Retrieval.
          This work proposes a Multiplicative Updates algorithm to compute NTD with the beta-divergence loss, often considered a better loss for audio processing.
          We notably show how to implement efficiently the multiplicative rules using tensor algebra, a naive approach being intractable.
          Finally, we show on a Music Structure Analysis task that unsupervised NTD fitted with beta-divergence loss outperforms earlier results obtained with the Euclidean loss.
        </p>
      </div>
    </div>
  </div>

  <!--<h2>Under review</h2>-->


<!--<h1>Pre-prints</h1>-->

<h1>Thesis</h1>

<div class="content_block">
  <h2>Multi-Channel Automatic Music Transcription Using Tensor Algebra</h2>
  Axel Marmoret, Master's thesis. Under the supervision of Nancy Bertin and Jérémy Cohen. arXiv preprint arXiv:2107.11250.
    <div class="box">
      <a href="javascript:void(0);" onclick="open_or_close('master_abstract')"><i class="fas fa-info-circle"></i></a>
      <a href="javascript:void(0);" onclick="open_or_close('master_bibtex')"><i class="fas fa-quote-left"></i></a>
      <a href="https://hal.archives-ouvertes.fr/hal-03301448" target="_blank"><i class="fas fa-unlock-alt"></i></a>
      <a href="https://gitlab.inria.fr/amarmore/nonnegative-factorization/" target="_blank"><i class="fab fa-gitlab"></i></a>
    </div>
<div id="master_bibtex" class="hidden_content_block">
  <div class="citation_content">
      <p>@article{marmoret2021multi,
  title={Multi-Channel Automatic Music Transcription Using Tensor Algebra},
  author={Marmoret, Axel and Bertin, Nancy and Cohen, J{\'e}r{\'e}my},
  journal={arXiv preprint arXiv:2107.11250},
  year={2019}}</p>
  </div>
</div>
<div id="master_abstract" class="hidden_content_block">
  <div class="citation_content">
      <p>Abstract: Music is an art, perceived in unique ways by every listener, coming from acoustic signals.
        In the meantime, standards as musical scores exist to describe it. Even if humans can make this transcription, it is costly in terms of time and efforts, even more with the explosion of information consecutively to the rise of the Internet.
        In that sense, researches are driven in the direction of Automatic Music Transcription.
        While this task is considered solved in the case of single notes, it is still open when notes superpose themselves, forming chords.
        This report aims at developing some of the existing techniques towards Music Transcription, particularly matrix factorization, and introducing the concept of multi-channel automatic music transcription.
        This concept will be explored with mathematical objects called tensors.
    </p>
  </div>
</div>
</div>

    <div></div>
    <footer>
      <div class="copyright">
        <p>For the theme: Copyright (c) 2020 by Naomi Bastian Weatherford <a target="_blank" class="inner-link" href="https://codepen.io/astronaomical/pen/KexYgb">(https://codepen.io/astronaomical/pen/KexYgb)</a></p>
      </div>
    </footer>
  </div>
</div>
</body></html>
